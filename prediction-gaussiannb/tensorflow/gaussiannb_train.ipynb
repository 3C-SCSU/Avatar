{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc01c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, re, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from gaussiannb_model import GaussianNBTF, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbaaeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_root = r\"/path/to/your/brainwave_readings/\"\n",
    "skip_dirs = { 'Group1-8channels' }\n",
    "use_pca = True\n",
    "pca_components = 32  # set None to disable or adjust\n",
    "var_smoothing = 1e-9  # GNB variance smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023cef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 files\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Load all EEG files recursively into a list of DataFrames\n",
    "core_dir = pathlib.Path(data_root)\n",
    "dfs = []\n",
    "for item in core_dir.rglob('*.txt'):\n",
    "    try:\n",
    "        if set(item.parts).isdisjoint(skip_dirs):\n",
    "            df = pd.read_csv(item, sep=',', header=4, on_bad_lines='skip')\n",
    "            df['src_filename'] = str(item)\n",
    "            dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to read {item}: {e}')\n",
    "print(f'Read {len(dfs)} files')\n",
    "eeg_data = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "print(eeg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34b5a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_txt\n",
      "backward    223058\n",
      "forward     226254\n",
      "landing     218567\n",
      "left        215514\n",
      "right       223213\n",
      "takeoff     222235\n",
      "Name: src_filename, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Robust label normalization from filenames\n",
    "assert not eeg_data.empty, 'No data loaded. Check data_root.'\n",
    "src = eeg_data['src_filename'].astype(str).str.lower()\n",
    "src_norm = src.str.replace(r'[\\s_\\-]+', '', regex=True)\n",
    "labels = pd.Series('', index=eeg_data.index)\n",
    "def assign_where(patterns, value, labels, src_norm):\n",
    "    m = pd.Series(False, index=src_norm.index)\n",
    "    for pat in patterns:\n",
    "        m = m | src_norm.str.contains(pat)\n",
    "    cond = (labels == '') & m\n",
    "    return labels.where(~cond, other=value)\n",
    "labels = assign_where(['backward','backwards'], 'backward', labels, src_norm)\n",
    "labels = assign_where(['fowward','forward'], 'forward', labels, src_norm)\n",
    "labels = assign_where(['landing'], 'landing', labels, src_norm)\n",
    "labels = assign_where(['left'], 'left', labels, src_norm)\n",
    "labels = assign_where(['right'], 'right', labels, src_norm)\n",
    "labels = assign_where(['takeoff','takeoff'], 'takeoff', labels, src_norm)\n",
    "eeg_data['label_txt'] = labels.astype(str)\n",
    "print(eeg_data.groupby(['label_txt'])['src_filename'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16b171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1328841, 26) classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Build feature matrix X and label vector y\n",
    "df = eeg_data.copy()\n",
    "df = df[df['label_txt'].astype(str).str.len() > 0]\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in ['Sample Index'] if c in num_cols]\n",
    "feature_cols = [c for c in num_cols if c not in drop_cols]\n",
    "feat = df[feature_cols].copy()\n",
    "feat = feat.replace([np.inf, -np.inf], np.nan)\n",
    "feat = feat.dropna(axis=1, how='all')\n",
    "med = feat.median(numeric_only=True)\n",
    "feat = feat.fillna(med)\n",
    "std = feat.std(numeric_only=True)\n",
    "keep = std[std > 0].index.tolist()\n",
    "feat = feat[keep]\n",
    "X = feat.to_numpy(dtype=np.float32)\n",
    "y_cat = df['label_txt'].astype('category')\n",
    "y = y_cat.cat.codes.to_numpy(dtype=np.int32)\n",
    "label_names = list(y_cat.cat.categories)\n",
    "print('X shape:', X.shape, 'classes:', len(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252dd07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test shapes: (1063072, 26) (265769, 26)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# z-score standardization (fit on train only)\n",
    "mu = X_train.mean(axis=0)\n",
    "sd = X_train.std(axis=0)\n",
    "sd[sd == 0] = 1.0\n",
    "X_train_z = (X_train - mu) / sd\n",
    "X_test_z  = (X_test  - mu) / sd\n",
    "# Optional PCA\n",
    "pca_components_ = None\n",
    "pca_mean_ = None\n",
    "if use_pca and pca_components is not None:\n",
    "    n_comp = int(min(pca_components, X_train_z.shape[1]))\n",
    "    pca = PCA(n_components=n_comp, whiten=True, random_state=42)\n",
    "    X_train_z = pca.fit_transform(X_train_z)\n",
    "    X_test_z = pca.transform(X_test_z)\n",
    "    pca_components_ = pca.components_.astype(np.float32)\n",
    "    pca_mean_ = pca.mean_.astype(np.float32)\n",
    "print('Train/Test shapes:', X_train_z.shape, X_test_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c92123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3192\n",
      "Confusion matrix:\n",
      " [[ 9863  1383  9492   727 22360   787]\n",
      " [ 3060 13227  7079   575 14465  6845]\n",
      " [ 1686  4566 19206   973 10753  6529]\n",
      " [ 1866  2546 10737  9355 17433  1166]\n",
      " [  552  1507 12045  3940 24993  1606]\n",
      " [ 1435  1334 12526  2707 18243  8202]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    backward       0.53      0.22      0.31     44612\n",
      "     forward       0.54      0.29      0.38     45251\n",
      "     landing       0.27      0.44      0.33     43713\n",
      "        left       0.51      0.22      0.30     43103\n",
      "       right       0.23      0.56      0.33     44643\n",
      "     takeoff       0.33      0.18      0.24     44447\n",
      "\n",
      "    accuracy                           0.32    265769\n",
      "   macro avg       0.40      0.32      0.32    265769\n",
      "weighted avg       0.40      0.32      0.32    265769\n",
      "\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    backward       0.53      0.22      0.31     44612\n",
      "     forward       0.54      0.29      0.38     45251\n",
      "     landing       0.27      0.44      0.33     43713\n",
      "        left       0.51      0.22      0.30     43103\n",
      "       right       0.23      0.56      0.33     44643\n",
      "     takeoff       0.33      0.18      0.24     44447\n",
      "\n",
      "    accuracy                           0.32    265769\n",
      "   macro avg       0.40      0.32      0.32    265769\n",
      "weighted avg       0.40      0.32      0.32    265769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Gaussian Naive Bayes (TensorFlow)\n",
    "model = GaussianNBTF(var_smoothing=var_smoothing)\n",
    "model.fit(X_train_z, y_train)\n",
    "y_pred = model.predict(X_test_z)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, target_names=label_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cb251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model to gaussiannb_trained.pth\n"
     ]
    }
   ],
   "source": [
    "# Save trained model with preprocessing metadata\n",
    "meta = {\n",
    "    'mu': mu.astype(np.float32),\n",
    "    'sd': sd.astype(np.float32),\n",
    "    'label_names': label_names,  # list[str]\n",
    "    'feature_cols': feature_cols,  # list[str]\n",
    "    'kept_feature_cols': keep,  # list[str]\n",
    "    'pca_components': pca_components_ if pca_components_ is not None else None,\n",
    "    'pca_mean': pca_mean_ if pca_mean_ is not None else None,\n",
    "}\n",
    "out_path = 'gaussiannb_trained.pth'\n",
    "save_model(out_path, model, meta)\n",
    "print(f'Saved trained model to {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model module to ensure latest save_model is in scope\n",
    "import importlib, gaussiannb_model\n",
    "importlib.reload(gaussiannb_model)\n",
    "from gaussiannb_model import GaussianNBTF, save_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
